# -*- coding: utf-8 -*-
"""unet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IWkvIPETrunSiswM-OQ-Wfq-zVid2MXx
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision

class Block(nn.Module):
  def __init__(self, in_channel, out_channel):
    super(Block,self).__init__()
    self.in_channel = in_channel
    self.out_channel = out_channel

    self.conv_block = nn.Sequential(
      nn.Conv2d(self.in_channel, self.out_channel, 3, 1, 1, bias=False),
      nn.BatchNorm2d(self.out_channel),
      nn.LeakyReLU(inplace=True),
      nn.Conv2d(self.out_channel, self.out_channel, 3, 1, 1, bias=False),
      nn.BatchNorm2d(self.out_channel),
      nn.LeakyReLU(inplace=True)
    )
    
  def forward(self, x):
    return self.conv_block(x)

class UNet(nn.Module):
  def __init__(self, in_channel= 3, out_channel= 3):
    super(UNet,self).__init__()
    self.in_channel = in_channel
    self.out_channel = out_channel
    self.channels = [64,128,256,512]

    # Network 
    self.encoder = nn.ModuleList()
    self.decoder = nn.ModuleList()
    self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)
    

    # Downsampling 
    in_channel = self.in_channel
    for channel in self.channels:
      self.encoder.append(Block(in_channel,channel))
      in_channel = channel
    
    # Bottleneck
    self.bottleneck = Block(self.channels[-1], self.channels[-1]*2)
    
    # Upsampling
    in_channel = self.channels[-1]*2
    for channel in reversed(self.channels):
      self.decoder.append(nn.ConvTranspose2d(in_channel, channel, kernel_size=2, stride=2))
      self.decoder.append(Block(in_channel, channel))
      in_channel = channel

    # Output layer
    self.output_layer = nn.Conv2d(self.channels[0],self.out_channel, kernel_size = 1)

  def forward(self, x): 
    feature_maps = []
    self.feat_map = []

    for encoder_block in self.encoder:
      x = encoder_block(x)
      feature_maps.append(x)
      x = self.pool(x)

    x = self.bottleneck(x)
    feature_maps = feature_maps[::-1]

    for idx in range(0, len(self.decoder), 2):
      x = self.decoder[idx](x)
      feature_map = feature_maps[idx//2]
      if feature_map.shape != x.shape:
        x = torchvision.transforms.functional.resize(x, size = feature_map.shape[2:])
      x = torch.cat((feature_map,x),dim = 1)
      x = self.decoder[idx+1](x)
  
    return self.output_layer(x)

if __name__ == '__main__':
  unet = UNet(3,13)
  x = torch.rand(16,3,150,200)
  print(unet.forward(x).shape)